{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_ids = data.user_id.unique()\n",
    "course_weeks = data.course_week.unique()\n",
    "\n",
    "for i, user_id in tqdm(user_ids.iteritems()):\n",
    "    print(user_id)\n",
    "    user_rows = data.loc[(data['user_id'] == user_id), :]\n",
    "\n",
    "    active_course_weeks = user_rows.loc[:, 'course_week'].unique()\n",
    "\n",
    "    zero_course_weeks = course_weeks[~course_weeks.isin(active_course_weeks.compute())]\n",
    "\n",
    "    started_week = user_rows.loc[:, 'user_started_week'].min().compute()\n",
    "    last_active_week = user_rows.loc[:, 'user_last_active_week'].min().compute()\n",
    "\n",
    "    completed_week = user_rows.loc[:, 'user_completed_week'].min().compute()\n",
    "\n",
    "#     zero_course_weeks = zero_course_weeks.between(left=0, right=int(last_active_week))\n",
    "    \n",
    "    zero_course_weeks = zero_course_weeks.loc[zero_course_weeks < int(last_active_week)]\n",
    "    \n",
    "\n",
    "    zero_course_weeks = zero_course_weeks.loc[zero_course_weeks > 0]\n",
    "\n",
    "    print(zero_course_weeks.compute())\n",
    "    \n",
    "    \n",
    "\n",
    "    zero_rows_df = pd.DataFrame(\n",
    "        np.zeros((zero_course_weeks.count().compute(), len(data.columns))),\n",
    "        columns=data.columns\n",
    "    )\n",
    "\n",
    "    zero_rows_df.loc[:, 'user_id'] = user_id\n",
    "    zero_rows_df.loc[:, 'course_week'] = zero_course_weeks\n",
    "    zero_rows_df.loc[:, 'user_started_week'] = started_week\n",
    "    zero_rows_df.loc[:, 'user_last_active_week'] = last_active_week\n",
    "    zero_rows_df.loc[:, 'user_completed_week'] = completed_week\n",
    "\n",
    "    \n",
    "    data = dd.concat([data, zero_rows_df], axis=0, interleave_partitions=True)\n",
    "#     raise ValueError('check')\n",
    "    print(data)\n",
    "#     data = data.append(zero_rows_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182112"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    46571\n",
       "1    19500\n",
       "Name: user_dropped_out_next_week, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/Microsoft+DAT206x+3T2017/model_data_l.csv')\n",
    "data['user_dropped_out_next_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('data/Microsoft+DAT247x+4T2017/model_data.csv')\n",
    "d_l = pd.read_csv('data/Microsoft+DAT247x+4T2017/model_data_l.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2533\n",
       "1     544\n",
       "Name: user_dropped_out_next_week, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['user_dropped_out_next_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    617\n",
       "1    544\n",
       "Name: user_dropped_out_next_week, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_l['user_dropped_out_next_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89470263243418913"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(d['user_dropped_out_next_week'], d['predicted_user_dropped_out_next_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = d['user_dropped_out_next_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3077,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.zeros(y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82320441988950277"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(d['user_dropped_out_next_week'], np.zeros(y_true.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Microsoft+DAT201x+4T2017\n",
      " did not have predictions.\n",
      "Course: Microsoft+DAT215.4x+4T2017\n",
      " did not have predictions.\n"
     ]
    }
   ],
   "source": [
    "model_accs = []\n",
    "base_accs = []\n",
    "precs = []\n",
    "recs = []\n",
    "f1s = []\n",
    "t1s = []\n",
    "cks = []\n",
    "course_ids = []\n",
    "\n",
    "\n",
    "with open('{}/top_course_ids.txt'.format('data')) as top_course_ids:\n",
    "    for top_course_id in top_course_ids:\n",
    "        if '4T2017' in top_course_id and 'JPN' not in top_course_id and 'DAT102x' not in top_course_id:\n",
    "            try:\n",
    "                final = pd.read_csv('data/{}/model_data_with_preds_l.csv'.format(top_course_id.strip()))\n",
    "                course_ids.append(top_course_id.strip())\n",
    "                y_true = final['user_dropped_out_next_week']\n",
    "                y_pred = final['predicted_user_dropped_out_next_week']\n",
    "            except:\n",
    "                print('Course: {} did not have predictions.'.format(top_course_id))\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            base_acc = np.zeros(y_true.shape)\n",
    "\n",
    "\n",
    "            model_accs.append(accuracy_score(y_true, y_pred))\n",
    "            base_accs.append(accuracy_score(y_true, base_acc))\n",
    "\n",
    "\n",
    "            precs.append(precision_score(y_true, y_pred))\n",
    "            recs.append(recall_score(y_true, y_pred))\n",
    "            \n",
    "            f1s.append(f1_score(y_true, y_pred))\n",
    "\n",
    "            conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "            t1s.append(conf_matrix[1][0] / len(y_true))\n",
    "\n",
    "            cks.append(cohen_kappa_score(y_true, y_pred))\n",
    "                \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(\n",
    "    [],\n",
    "    columns=[\n",
    "        'course_id', 'model_accuracy', 'base_accuracy (all 0)',\n",
    "        'precision', 'recall', 'f1_score', 'num_false_negatives',\n",
    "        'cohens_kappa'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores['course_id'] = course_ids\n",
    "scores['model_accuracy'] = model_accs\n",
    "scores['base_accuracy (all 0)'] = base_accs\n",
    "# scores['precision'] = precs\n",
    "scores['recall'] = recs\n",
    "scores['f1_score'] = f1s\n",
    "scores['false_neg_perc'] = t1s\n",
    "scores['cohens_kappa'] = cks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>base_accuracy (all 0)</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>cohens_kappa</th>\n",
       "      <th>false_neg_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.684881</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.891028</td>\n",
       "      <td>0.757141</td>\n",
       "      <td>0.307221</td>\n",
       "      <td>0.061064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.039352</td>\n",
       "      <td>0.092054</td>\n",
       "      <td>0.047550</td>\n",
       "      <td>0.052653</td>\n",
       "      <td>0.053306</td>\n",
       "      <td>0.029501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.615760</td>\n",
       "      <td>0.244774</td>\n",
       "      <td>0.744044</td>\n",
       "      <td>0.665376</td>\n",
       "      <td>0.183833</td>\n",
       "      <td>0.019920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.648871</td>\n",
       "      <td>0.346731</td>\n",
       "      <td>0.868089</td>\n",
       "      <td>0.719372</td>\n",
       "      <td>0.278210</td>\n",
       "      <td>0.040122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.684636</td>\n",
       "      <td>0.461572</td>\n",
       "      <td>0.896361</td>\n",
       "      <td>0.748100</td>\n",
       "      <td>0.314175</td>\n",
       "      <td>0.056655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.716498</td>\n",
       "      <td>0.495224</td>\n",
       "      <td>0.928215</td>\n",
       "      <td>0.809384</td>\n",
       "      <td>0.338812</td>\n",
       "      <td>0.073257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.769920</td>\n",
       "      <td>0.580146</td>\n",
       "      <td>0.971510</td>\n",
       "      <td>0.855172</td>\n",
       "      <td>0.408120</td>\n",
       "      <td>0.166392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_accuracy  base_accuracy (all 0)     recall   f1_score  \\\n",
       "count       34.000000              34.000000  34.000000  34.000000   \n",
       "mean         0.684881               0.433035   0.891028   0.757141   \n",
       "std          0.039352               0.092054   0.047550   0.052653   \n",
       "min          0.615760               0.244774   0.744044   0.665376   \n",
       "25%          0.648871               0.346731   0.868089   0.719372   \n",
       "50%          0.684636               0.461572   0.896361   0.748100   \n",
       "75%          0.716498               0.495224   0.928215   0.809384   \n",
       "max          0.769920               0.580146   0.971510   0.855172   \n",
       "\n",
       "       cohens_kappa  false_neg_perc  \n",
       "count     34.000000       34.000000  \n",
       "mean       0.307221        0.061064  \n",
       "std        0.053306        0.029501  \n",
       "min        0.183833        0.019920  \n",
       "25%        0.278210        0.040122  \n",
       "50%        0.314175        0.056655  \n",
       "75%        0.338812        0.073257  \n",
       "max        0.408120        0.166392  "
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cntk.device import try_set_default_device, gpu\n",
    "try_set_default_device(gpu(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from cntk.device import try_set_default_device, gpu\n",
    "try_set_default_device(gpu(0))\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Activation, Dense, Dropout, Input, Average\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.utils import plot_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from pipeline.util import *\n",
    "\n",
    "\n",
    "def get_data_path():\n",
    "    return './data'\n",
    "\n",
    "def save_df_to_file(dataframe, name, course_id, type='csv'):\n",
    "    \"\"\"\n",
    "    Save a dataframe to a csv file in the data/{course_id}/ directory\n",
    "    \"\"\"\n",
    "\n",
    "    path = '{}/{}/{}'.format(get_data_path(), course_id, name)\n",
    "\n",
    "    if type == 'excel':\n",
    "        path += '.xlsx'\n",
    "        create_directory_safe(path)\n",
    "        dataframe.to_excel(path)\n",
    "    else:\n",
    "        path += '.csv'\n",
    "        create_directory_safe(path)\n",
    "        dataframe.to_csv(path, index=False)\n",
    "        \n",
    "        \n",
    "def get_data(current_course_id):\n",
    "    \"\"\"\n",
    "    TODO Fix how this training data is sampled\n",
    "    e.g. bootstrap sampling of a random number of courses\n",
    "    to get a total of > 1 million training samples\n",
    "    \"\"\"\n",
    "\n",
    "    # train = pd.read_csv('{}/{}/model_data.csv'.format(get_data_path(), 'Microsoft+DAT206x+3T2017'))\n",
    "    train = None\n",
    "    past_course_ids = [f for f in os.listdir(get_data_path()) if not f.startswith('.')]\n",
    "    try:\n",
    "        past_course_ids.remove(current_course_id)\n",
    "    except ValueError:\n",
    "        print('Not in list')\n",
    "\n",
    "    for course_id in past_course_ids:\n",
    "        if '4T2017' not in course_id:\n",
    "            try:\n",
    "                # course_run_data = pd.read_csv('{}/{}/model_data.csv'.format(get_data_path(), course_id))\n",
    "                path = '{}/{}/model_data_l.csv'.format(get_data_path(), course_id)\n",
    "                course_run_data = pd.read_csv(path)\n",
    "            except Exception:\n",
    "                print('model_data.csv does not exist for course: ', course_id)\n",
    "                continue\n",
    "                # pass                \n",
    "            if train is None:\n",
    "                train = course_run_data\n",
    "            else:\n",
    "                train = train.append(course_run_data)\n",
    "\n",
    "    print('Training data done.')\n",
    "\n",
    "    train = train.reset_index(drop=True)\n",
    "    # test = pd.read_csv('{}/{}/model_data.csv'.format(get_data_path(), current_course_id))\n",
    "    test = pd.read_csv('{}/{}/model_data_l.csv'.format(get_data_path(), current_course_id))\n",
    "\n",
    "    X_cols = [\n",
    "        'course_week', 'num_video_plays', 'num_problems_attempted',\n",
    "        'num_problems_correct', 'num_subsections_viewed', 'num_forum_posts',\n",
    "        'num_forum_votes', 'avg_forum_sentiment', \n",
    "        'user_started_week', 'user_active_previous_week'\n",
    "    ]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train[X_cols])\n",
    "\n",
    "    X_train = scaler.transform(train[X_cols])\n",
    "    X_test = scaler.transform(test[X_cols])\n",
    "\n",
    "    X_train = np.array(X_train).astype(np.float32)\n",
    "    X_test = np.array(X_test).astype(np.float32)\n",
    "\n",
    "    y_train = np.array(train['user_dropped_out_next_week']).astype(np.float32)\n",
    "    y_test = np.array(test['user_dropped_out_next_week']).astype(np.float32)\n",
    "\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def _create_pivot_table(df, val_col):\n",
    "    df_pivot = df.pivot_table(\n",
    "        index='user_id', columns=['course_week'], values=val_col, fill_value=-1\n",
    "    )\n",
    "    df_colored = df_pivot.style.applymap(_cell_colors)\n",
    "    return df_colored\n",
    "\n",
    "def _cell_colors(s):\n",
    "    ret = 'background-color: {}'\n",
    "    if s == 0:\n",
    "        ret = ret.format('#228b22')\n",
    "    elif s == 1:\n",
    "        ret = ret.format('#dc143c')\n",
    "    else:\n",
    "        ret = ret.format('#d3d3d3')\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(model_input, hidden_layers_conf=[], name=''):\n",
    "    # create model\n",
    "    model = None\n",
    "    \n",
    "    for i, layer in enumerate(hidden_layers_conf):\n",
    "        \n",
    "        if i == 0:            \n",
    "            model = Dense(layer['n_units'])(model_input)            \n",
    "                \n",
    "        model = BatchNormalization()(model)\n",
    "        model = Activation('relu')(model)\n",
    "        model = Dropout(layer.get('dropout', 0.2))(model)\n",
    "    \n",
    "    model = Dense(1)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    predictions = Activation('sigmoid')(model)\n",
    "    \n",
    "    model = Model(inputs=model_input, outputs=predictions)\n",
    "    if name:\n",
    "        model.name = name\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_and_train(model, x_train, y_train, optimizer='adam', metrics=['accuracy'], num_epochs=20, batch_size=100): \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=metrics) \n",
    "    filepath = 'weights/' + model.name + '.{epoch:02d}-{loss:.2f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath, monitor='loss', verbose=0, save_weights_only=True, save_best_only=True, mode='auto', period=1\n",
    "    )\n",
    "    \n",
    "    history = model.fit(x=x_train,\n",
    "                        y=y_train, \n",
    "                        batch_size=batch_size, \n",
    "                        epochs=num_epochs, \n",
    "                        verbose=1,\n",
    "                        class_weight={ 0: 1., 1: 2 },\n",
    "                        callbacks=[checkpoint])\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def ensemble_models(models, model_input):\n",
    "    # collect outputs of models in a list\n",
    "    print(models[0].outputs)\n",
    "    model_outputs = [model.outputs[0] for model in models]\n",
    "    \n",
    "    print('OUTPUTS:')\n",
    "    print(model_outputs)\n",
    "\n",
    "    # averaging outputs\n",
    "    avg = Average()(model_outputs)\n",
    "    \n",
    "    print('AVG:')\n",
    "    print(avg)\n",
    "\n",
    "    # build model from same input and avg output\n",
    "    model_ens = Model(inputs=model_input, outputs=avg, name='ensemble') \n",
    "    print(model_ens)\n",
    "   \n",
    "    return model_ens\n",
    "\n",
    "\n",
    "def fit_score_predict(course_id, train=False):\n",
    "\n",
    "    print('GETTING DATA: ')\n",
    "    X_train, y_train, X_test, y_test = get_data(course_id)\n",
    "    print('Done.')\n",
    "\n",
    "    input_shape = (X_train.shape[1],)\n",
    "    model_input = Input(shape=input_shape)\n",
    "    \n",
    "    models = []\n",
    "    batch_size = 256\n",
    "    \n",
    "    if not train:\n",
    "        current_date_string = datetime.strftime(datetime.today(), '%Y-%m-%d')\n",
    "        model = load_model('model.h5-{}'.format('2018-01-23'))\n",
    "    else:\n",
    "        adam = optimizers.Adam(lr=0.01)\n",
    "        layers_conf = [\n",
    "            {\n",
    "                'n_units': 8,\n",
    "                'dropout': 0.2,\n",
    "                'input_dim': 10\n",
    "            },\n",
    "            {\n",
    "                'n_units': 8,\n",
    "                'dropout': 0.25\n",
    "            },\n",
    "            {\n",
    "                'n_units': 6,\n",
    "                'dropout': 0.2\n",
    "            },\n",
    "            {\n",
    "                'n_units': 2,\n",
    "                'dropout': 0.\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        print('Fitting model')\n",
    "        \n",
    "        kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "        \n",
    "        \n",
    "        for i, (train_ind, val_ind) in enumerate(kfold.split(X_train, y_train)):\n",
    "            \n",
    "            model = create_model(model_input, \n",
    "                                 hidden_layers_conf=layers_conf, \n",
    "                                 name='kfold-{}'.format(i))\n",
    "            \n",
    "            _ = compile_and_train(model,\n",
    "                                  num_epochs=3,\n",
    "                                  batch_size=batch_size,\n",
    "                                  train_data=(X_train[train_ind], y_train[train_ind]), \n",
    "                                  validation_data=(X_train[val_ind], y_train[val_ind]))            \n",
    "            \n",
    "            scores = model.evaluate(X_train[val_ind], y_train[val_ind], batch_size)\n",
    "            \n",
    "            models.append(model)\n",
    "        \n",
    "    print('Evaluating model on data for course: {}'.format(course_id))\n",
    "    \n",
    "    print(model_input)\n",
    "    ensemble = ensemble_models(models, model_input)\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "    try:\n",
    "        current_date_string = datetime.strftime(datetime.today(), '%Y-%m-%d')\n",
    "        ensemble.save('model-ensemble-{}.h5'.format(current_date_string))\n",
    "    except:\n",
    "        print('FAILED TO SAVE MODEL')\n",
    "    \n",
    "#     score = ensemble.evaluate(X_test, y_test, batch_size)\n",
    "#     print('Model score', score)\n",
    "\n",
    "    preds = ensemble.predict(X_test, batch_size)\n",
    "    final_preds = np.round(preds)\n",
    "\n",
    "    print('PREDS: ', final_preds)\n",
    "    print('Y_TEST: ', y_test)\n",
    "\n",
    "    conf_matrix = metrics.confusion_matrix(y_test, final_preds)\n",
    "\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    total = len(y_test)\n",
    "    final_acc = (tn + tp) / total\n",
    "\n",
    "    test_data_orig = pd.read_csv('{}/{}/model_data_l.csv'.format(get_data_path(), course_id))\n",
    "    test_data_orig['predicted_user_dropped_out_next_week'] = final_preds\n",
    "    \n",
    "\n",
    "    pred_pivot = _create_pivot_table(test_data_orig, 'predicted_user_dropped_out_next_week')\n",
    "    real_pivot = _create_pivot_table(test_data_orig, 'user_dropped_out_next_week')\n",
    "\n",
    "    # save_df_to_file(pred_pivot, 'predicted_dropouts', course_id, type='excel')\n",
    "    # save_df_to_file(real_pivot, 'real_dropouts', course_id, type='excel')\n",
    "    # save_df_to_file(test_data_orig, 'model_data_with_preds', course_id)\n",
    "\n",
    "#     save_df_to_file(pred_pivot, 'predicted_dropouts_l', course_id, type='excel')\n",
    "#     save_df_to_file(real_pivot, 'real_dropouts_l', course_id, type='excel')\n",
    "    save_df_to_file(test_data_orig, 'model_data_with_preds_l', course_id)\n",
    "\n",
    "    print('ACCURACY: ', final_acc)\n",
    "    print('CONFUSION MATRIX: ')\n",
    "    print(conf_matrix)\n",
    "    print(conf_matrix / len(y_test))\n",
    "\n",
    "    return (final_preds, final_acc, conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING DATA: \n",
      "model_data.csv does not exist for course:  Microsoft+DAT215.4x+1T2017\n",
      "model_data.csv does not exist for course:  _SUCCESS\n",
      "model_data.csv does not exist for course:  Microsoft+DAT206x+JPN+1T2017\n",
      "model_data.csv does not exist for course:  Microsoft+DAT206x+6T2016\n",
      "model_data.csv does not exist for course:  Microsoft+DAT206x+1T2018\n",
      "model_data.csv does not exist for course:  Microsoft+DAT215.3x+3T2017\n",
      "model_data.csv does not exist for course:  Microsoft+DAT206x+JPN+2T2017\n",
      "model_data.csv does not exist for course:  Microsoft+DAT207x+1T2018\n",
      "model_data.csv does not exist for course:  weights\n",
      "model_data.csv does not exist for course:  top_course_ids.txt\n",
      "model_data.csv does not exist for course:  Microsoft+DAT205x+3T2016\n",
      "Training data done.\n",
      "Done.\n",
      "(10,)\n",
      "Fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabirkhan/Documents/ML_Experiments/py35/lib/python3.5/site-packages/keras/backend/cntk_backend.py:2337: UserWarning: CNTK backend warning: CNTK version not detected. Will using CNTK 2.0 GA as default.\n",
      "  'CNTK backend warning: CNTK version not detected. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "    800/1317788 [..............................] - ETA: 5:29 - loss: 1.1895 - acc: 0.5062 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabirkhan/Documents/ML_Experiments/py35/lib/python3.5/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input75544\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317788/1317788 [==============================] - 100s 76us/step - loss: 0.6831 - acc: 0.7302\n",
      "658894/658894 [==============================] - 5s 8us/step\n",
      "acc: 75.15%\n",
      "Epoch 1/1\n",
      "    800/1317788 [..............................] - ETA: 5:41 - loss: 1.3244 - acc: 0.5400 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabirkhan/Documents/ML_Experiments/py35/lib/python3.5/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input78354\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317788/1317788 [==============================] - 100s 76us/step - loss: 0.7114 - acc: 0.7264\n",
      "658894/658894 [==============================] - 5s 8us/step\n",
      "acc: 73.85%\n",
      "Epoch 1/1\n",
      "    700/1317788 [..............................] - ETA: 6:47 - loss: 1.2663 - acc: 0.4243 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabirkhan/Documents/ML_Experiments/py35/lib/python3.5/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input81164\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317788/1317788 [==============================] - 100s 76us/step - loss: 0.6976 - acc: 0.7264\n",
      "658894/658894 [==============================] - 5s 8us/step\n",
      "acc: 77.02%\n",
      "AVERAGE ACCURACY MANUAL: 75.34% (+/- 1.30%)\n",
      "Evaluating model on data for course: Microsoft+DAT206x+4T2017\n",
      "Input('input_18', [#], [10])\n",
      "[Composite(StableSigmoid): Input('input_18', [#], [10]) -> Output('StableSigmoid75535_Output_0', [#], [1])]\n",
      "OUTPUTS:\n",
      "[Composite(StableSigmoid): Input('input_18', [#], [10]) -> Output('StableSigmoid75535_Output_0', [#], [1]), Composite(StableSigmoid): Input('input_18', [#], [10]) -> Output('StableSigmoid78345_Output_0', [#], [1]), Composite(StableSigmoid): Input('input_18', [#], [10]) -> Output('StableSigmoid81155_Output_0', [#], [1])]\n",
      "AVG:\n",
      "Composite(input_18: Tensor[10]) -> Tensor[1]\n",
      "<keras.engine.training.Model object at 0x7fa24428fe10>\n",
      "Done\n",
      "PREDS:  [[ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " ..., \n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "Y_TEST:  [ 0.  0.  1. ...,  0.  1.  1.]\n",
      "ACCURACY:  0.740426738133\n",
      "CONFUSION MATRIX: \n",
      "[[ 9330  7744]\n",
      " [ 2329 19403]]\n",
      "[[ 0.24042674  0.19955677]\n",
      " [ 0.06001649  0.5       ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        ..., \n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.]], dtype=float32), 0.74042673813327831, array([[ 9330,  7744],\n",
       "        [ 2329, 19403]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_score_predict('Microsoft+DAT206x+4T2017', train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "ensemble = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = np.array([1,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,1,1,0,0,1,1,1,0,1,0])\n",
    "y_pred = np.array([1,1,1,0,0,1,1,0,0,1,1,0,0,1,1,1,1,1,0,0,1,1,0,0,1,1,0,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83333333333333337"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = metrics.confusion_matrix(y_true, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88235294117647056"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity = tp / float(fn + tp)\n",
    "sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88235294117647056"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11764705882352941"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn / float(tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82579185520361975"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049019607843137192"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_true, y_pred) - metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>course_week</th>\n",
       "      <th>num_video_plays</th>\n",
       "      <th>num_problems_attempted</th>\n",
       "      <th>num_problems_correct</th>\n",
       "      <th>num_subsections_viewed</th>\n",
       "      <th>num_forum_posts</th>\n",
       "      <th>num_forum_votes</th>\n",
       "      <th>avg_forum_sentiment</th>\n",
       "      <th>user_started_week</th>\n",
       "      <th>user_last_active_week</th>\n",
       "      <th>user_completed_week</th>\n",
       "      <th>user_active_previous_week</th>\n",
       "      <th>user_dropped_out_next_week</th>\n",
       "      <th>predicted_user_dropped_out_next_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54812.970000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>2.670000</td>\n",
       "      <td>5.460000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.210000</td>\n",
       "      <td>9.020000</td>\n",
       "      <td>-0.780000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27943.162048</td>\n",
       "      <td>4.211576</td>\n",
       "      <td>19.145113</td>\n",
       "      <td>11.704199</td>\n",
       "      <td>8.520984</td>\n",
       "      <td>8.832241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.962032</td>\n",
       "      <td>5.235813</td>\n",
       "      <td>1.547758</td>\n",
       "      <td>0.429235</td>\n",
       "      <td>0.479372</td>\n",
       "      <td>0.422953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1131.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33522.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58444.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82020.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>84693.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id  course_week  num_video_plays  num_problems_attempted  \\\n",
       "count    100.000000   100.000000       100.000000              100.000000   \n",
       "mean   54812.970000     7.000000         8.700000                3.960000   \n",
       "std    27943.162048     4.211576        19.145113               11.704199   \n",
       "min     1131.000000     1.000000         0.000000                0.000000   \n",
       "25%    33522.000000     3.000000         0.000000                0.000000   \n",
       "50%    58444.000000     7.000000         1.000000                0.000000   \n",
       "75%    82020.000000    10.000000         8.500000                2.250000   \n",
       "max    84693.000000    16.000000       111.000000              101.000000   \n",
       "\n",
       "       num_problems_correct  num_subsections_viewed  num_forum_posts  \\\n",
       "count            100.000000              100.000000            100.0   \n",
       "mean               2.670000                5.460000              0.0   \n",
       "std                8.520984                8.832241              0.0   \n",
       "min                0.000000                0.000000              0.0   \n",
       "25%                0.000000                0.000000              0.0   \n",
       "50%                0.000000                4.000000              0.0   \n",
       "75%                2.000000                7.000000              0.0   \n",
       "max               76.000000               68.000000              0.0   \n",
       "\n",
       "       num_forum_votes  avg_forum_sentiment  user_started_week  \\\n",
       "count            100.0                100.0         100.000000   \n",
       "mean               0.0                  0.0           5.210000   \n",
       "std                0.0                  0.0           2.962032   \n",
       "min                0.0                  0.0           1.000000   \n",
       "25%                0.0                  0.0           3.000000   \n",
       "50%                0.0                  0.0           6.000000   \n",
       "75%                0.0                  0.0           7.000000   \n",
       "max                0.0                  0.0          13.000000   \n",
       "\n",
       "       user_last_active_week  user_completed_week  user_active_previous_week  \\\n",
       "count             100.000000           100.000000                 100.000000   \n",
       "mean                9.020000            -0.780000                   0.240000   \n",
       "std                 5.235813             1.547758                   0.429235   \n",
       "min                 1.000000            -1.000000                   0.000000   \n",
       "25%                 4.000000            -1.000000                   0.000000   \n",
       "50%                 8.000000            -1.000000                   0.000000   \n",
       "75%                15.000000            -1.000000                   0.000000   \n",
       "max                16.000000            10.000000                   1.000000   \n",
       "\n",
       "       user_dropped_out_next_week  predicted_user_dropped_out_next_week  \n",
       "count                  100.000000                            100.000000  \n",
       "mean                     0.650000                              0.770000  \n",
       "std                      0.479372                              0.422953  \n",
       "min                      0.000000                              0.000000  \n",
       "25%                      0.000000                              1.000000  \n",
       "50%                      1.000000                              1.000000  \n",
       "75%                      1.000000                              1.000000  \n",
       "max                      1.000000                              1.000000  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_video_plays</th>\n",
       "      <th>num_problems_attempted</th>\n",
       "      <th>num_problems_correct</th>\n",
       "      <th>num_subsections_viewed</th>\n",
       "      <th>num_forum_posts</th>\n",
       "      <th>num_forum_votes</th>\n",
       "      <th>avg_forum_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.700000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>2.670000</td>\n",
       "      <td>5.460000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.145113</td>\n",
       "      <td>11.704199</td>\n",
       "      <td>8.520984</td>\n",
       "      <td>8.832241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>111.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_video_plays  num_problems_attempted  num_problems_correct  \\\n",
       "count       100.000000              100.000000            100.000000   \n",
       "mean          8.700000                3.960000              2.670000   \n",
       "std          19.145113               11.704199              8.520984   \n",
       "min           0.000000                0.000000              0.000000   \n",
       "25%           0.000000                0.000000              0.000000   \n",
       "50%           1.000000                0.000000              0.000000   \n",
       "75%           8.500000                2.250000              2.000000   \n",
       "max         111.000000              101.000000             76.000000   \n",
       "\n",
       "       num_subsections_viewed  num_forum_posts  num_forum_votes  \\\n",
       "count              100.000000            100.0            100.0   \n",
       "mean                 5.460000              0.0              0.0   \n",
       "std                  8.832241              0.0              0.0   \n",
       "min                  0.000000              0.0              0.0   \n",
       "25%                  0.000000              0.0              0.0   \n",
       "50%                  4.000000              0.0              0.0   \n",
       "75%                  7.000000              0.0              0.0   \n",
       "max                 68.000000              0.0              0.0   \n",
       "\n",
       "       avg_forum_sentiment  \n",
       "count                100.0  \n",
       "mean                   0.0  \n",
       "std                    0.0  \n",
       "min                    0.0  \n",
       "25%                    0.0  \n",
       "50%                    0.0  \n",
       "75%                    0.0  \n",
       "max                    0.0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[['num_video_plays', 'num_problems_attempted',\n",
    "       'num_problems_correct', 'num_subsections_viewed', 'num_forum_posts',\n",
    "       'num_forum_votes', 'avg_forum_sentiment']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizers.Adam(lr=0.01, decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.01 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06666666666666667\n",
      "0.04444444444444444\n",
      "0.029629629629629624\n",
      "0.019753086419753083\n",
      "0.013168724279835387\n",
      "0.008779149519890258\n",
      "0.0058527663465935045\n",
      "0.003901844231062336\n",
      "0.0026012294873748905\n",
      "0.0017341529915832603\n"
     ]
    }
   ],
   "source": [
    "lr = 0.1\n",
    "decay_rate = 0.05\n",
    "num_epochs = 10\n",
    "for i in range(num_epochs):\n",
    "    lr *= (1. / (1. + decay_rate * num_epochs))\n",
    "    print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "from azure.storage.file import FileService\n",
    "import azure.mgmt.batchai.models as models\n",
    "\n",
    "# utilities.py contains helper functions used by different notebooks\n",
    "from batch_ai import utilities\n",
    "\n",
    "cfg = utilities.Configuration('./batch_ai/configuration.json')\n",
    "client = utilities.create_batchai_client(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'https://learnerattrition.file.core.windows.net/batchaisample/fd74930d-c060-4ff4-a7f1-9470f7ad7f8f/learner-attrition-supp/jobs/la_01_30_2018_031346/4d6e71b4-e9d6-4b25-8aa0-3f7c136f09c7/outputs/Models/'\n",
    "model_file_name = 'model.h5'\n",
    "# utilities.download_file(model_file, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = FileService(cfg.storage_account_name, cfg.storage_account_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./model-stream.h5', 'wb') as stream:\n",
    "    service.get_file_to_stream('batchaisample', model_path, model_file_name, stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/Microsoft+DAT206x+1T2017/model_data_l.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>course_week</th>\n",
       "      <th>num_video_plays</th>\n",
       "      <th>num_problems_attempted</th>\n",
       "      <th>num_problems_correct</th>\n",
       "      <th>num_subsections_viewed</th>\n",
       "      <th>num_forum_posts</th>\n",
       "      <th>num_forum_votes</th>\n",
       "      <th>avg_forum_sentiment</th>\n",
       "      <th>user_started_week</th>\n",
       "      <th>user_last_active_week</th>\n",
       "      <th>user_completed_week</th>\n",
       "      <th>user_active_previous_week</th>\n",
       "      <th>user_dropped_out_next_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1102</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1102</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1102</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1102</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1102</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1547</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1547</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2067</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  course_week  num_video_plays  num_problems_attempted  \\\n",
       "0     1102         11.0              1.0                     0.0   \n",
       "1     1102         12.0              0.0                     0.0   \n",
       "2     1102         13.0              0.0                     0.0   \n",
       "3     1102         14.0              0.0                     0.0   \n",
       "4     1102         15.0              0.0                     0.0   \n",
       "5     1102         16.0              0.0                     0.0   \n",
       "6     1547          2.0              0.0                     0.0   \n",
       "7     1547          7.0              0.0                     1.0   \n",
       "8     2067          9.0             26.0                    12.0   \n",
       "9     3393          1.0             91.0                    37.0   \n",
       "\n",
       "   num_problems_correct  num_subsections_viewed  num_forum_posts  \\\n",
       "0                   0.0                     4.0              0.0   \n",
       "1                   0.0                     0.0              0.0   \n",
       "2                   0.0                     0.0              0.0   \n",
       "3                   0.0                     0.0              0.0   \n",
       "4                   0.0                     0.0              0.0   \n",
       "5                   0.0                     1.0              0.0   \n",
       "6                   0.0                     1.0              0.0   \n",
       "7                   1.0                    10.0              0.0   \n",
       "8                   6.0                    45.0              0.0   \n",
       "9                  32.0                    22.0              0.0   \n",
       "\n",
       "   num_forum_votes  avg_forum_sentiment  user_started_week  \\\n",
       "0              0.0                  0.0               11.0   \n",
       "1              0.0                  0.0               11.0   \n",
       "2              0.0                  0.0               11.0   \n",
       "3              0.0                  0.0               11.0   \n",
       "4              0.0                  0.0               11.0   \n",
       "5              0.0                  0.0               11.0   \n",
       "6              0.0                  0.0                7.0   \n",
       "7              0.0                  0.0                7.0   \n",
       "8              0.0                  0.0                9.0   \n",
       "9              0.0                  0.0                1.0   \n",
       "\n",
       "   user_last_active_week  user_completed_week  user_active_previous_week  \\\n",
       "0                   16.0                 -1.0                        0.0   \n",
       "1                   16.0                 -1.0                        1.0   \n",
       "2                   16.0                 -1.0                        0.0   \n",
       "3                   16.0                 -1.0                        0.0   \n",
       "4                   16.0                 -1.0                        0.0   \n",
       "5                   16.0                 -1.0                        0.0   \n",
       "6                    7.0                 -1.0                        0.0   \n",
       "7                    7.0                 -1.0                        0.0   \n",
       "8                    9.0                 -1.0                        0.0   \n",
       "9                   14.0                  6.0                        0.0   \n",
       "\n",
       "   user_dropped_out_next_week  \n",
       "0                         0.0  \n",
       "1                         0.0  \n",
       "2                         1.0  \n",
       "3                         1.0  \n",
       "4                         1.0  \n",
       "5                         1.0  \n",
       "6                         1.0  \n",
       "7                         1.0  \n",
       "8                         1.0  \n",
       "9                         0.0  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>course_week</th>\n",
       "      <th>num_video_plays</th>\n",
       "      <th>num_problems_attempted</th>\n",
       "      <th>num_problems_correct</th>\n",
       "      <th>num_subsections_viewed</th>\n",
       "      <th>num_forum_posts</th>\n",
       "      <th>num_forum_votes</th>\n",
       "      <th>avg_forum_sentiment</th>\n",
       "      <th>user_started_week</th>\n",
       "      <th>user_last_active_week</th>\n",
       "      <th>user_completed_week</th>\n",
       "      <th>user_active_previous_week</th>\n",
       "      <th>user_dropped_out_next_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.595070e+05</td>\n",
       "      <td>159507.000000</td>\n",
       "      <td>159507.000000</td>\n",
       "      <td>159507.000000</td>\n",
       "      <td>159507.000000</td>\n",
       "      <td>159507.000000</td>\n",
       "      <td>159507.000000</td>\n",
       "      <td>159507.000000</td>\n",
       "      <td>159507.000000</td>\n",
       "      <td>159507.000000</td>\n",
       "      <td>159507.000000</td>\n",
       "      <td>159507.000000</td>\n",
       "      <td>159507.000000</td>\n",
       "      <td>159507.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.032366e+07</td>\n",
       "      <td>13.312989</td>\n",
       "      <td>5.239538</td>\n",
       "      <td>4.111932</td>\n",
       "      <td>2.987023</td>\n",
       "      <td>4.403681</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>5.217489</td>\n",
       "      <td>21.691525</td>\n",
       "      <td>0.607321</td>\n",
       "      <td>0.165397</td>\n",
       "      <td>0.702665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.931041e+06</td>\n",
       "      <td>10.633514</td>\n",
       "      <td>22.624566</td>\n",
       "      <td>14.612374</td>\n",
       "      <td>11.344113</td>\n",
       "      <td>10.030069</td>\n",
       "      <td>0.017953</td>\n",
       "      <td>0.654222</td>\n",
       "      <td>0.082396</td>\n",
       "      <td>3.418082</td>\n",
       "      <td>15.759889</td>\n",
       "      <td>4.342588</td>\n",
       "      <td>0.371540</td>\n",
       "      <td>0.457087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.102000e+03</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.060308e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.227390e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.325299e+07</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.416629e+07</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>1340.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>241.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id    course_week  num_video_plays  num_problems_attempted  \\\n",
       "count  1.595070e+05  159507.000000    159507.000000           159507.000000   \n",
       "mean   1.032366e+07      13.312989         5.239538                4.111932   \n",
       "std    3.931041e+06      10.633514        22.624566               14.612374   \n",
       "min    1.102000e+03      -1.000000         0.000000                0.000000   \n",
       "25%    8.060308e+06       6.000000         0.000000                0.000000   \n",
       "50%    1.227390e+07      10.000000         0.000000                0.000000   \n",
       "75%    1.325299e+07      17.000000         1.000000                0.000000   \n",
       "max    1.416629e+07      55.000000      1340.000000              203.000000   \n",
       "\n",
       "       num_problems_correct  num_subsections_viewed  num_forum_posts  \\\n",
       "count         159507.000000           159507.000000    159507.000000   \n",
       "mean               2.987023                4.403681         0.000542   \n",
       "std               11.344113               10.030069         0.017953   \n",
       "min                0.000000                0.000000        -0.800000   \n",
       "25%                0.000000                0.000000         0.000000   \n",
       "50%                0.000000                0.000000         0.000000   \n",
       "75%                0.000000                5.000000         0.000000   \n",
       "max              200.000000              241.000000         1.000000   \n",
       "\n",
       "       num_forum_votes  avg_forum_sentiment  user_started_week  \\\n",
       "count    159507.000000        159507.000000      159507.000000   \n",
       "mean          0.017429             0.000796           5.217489   \n",
       "std           0.654222             0.082396           3.418082   \n",
       "min           0.000000             0.000000          -1.000000   \n",
       "25%           0.000000             0.000000           2.000000   \n",
       "50%           0.000000             0.000000           5.000000   \n",
       "75%           0.000000             0.000000           8.000000   \n",
       "max         137.000000            27.000000          13.000000   \n",
       "\n",
       "       user_last_active_week  user_completed_week  user_active_previous_week  \\\n",
       "count          159507.000000        159507.000000              159507.000000   \n",
       "mean               21.691525             0.607321                   0.165397   \n",
       "std                15.759889             4.342588                   0.371540   \n",
       "min                -1.000000            -1.000000                   0.000000   \n",
       "25%                 9.000000            -1.000000                   0.000000   \n",
       "50%                15.000000            -1.000000                   0.000000   \n",
       "75%                35.000000            -1.000000                   0.000000   \n",
       "max                55.000000            13.000000                   1.000000   \n",
       "\n",
       "       user_dropped_out_next_week  \n",
       "count               159507.000000  \n",
       "mean                     0.702665  \n",
       "std                      0.457087  \n",
       "min                      0.000000  \n",
       "25%                      0.000000  \n",
       "50%                      1.000000  \n",
       "75%                      1.000000  \n",
       "max                      1.000000  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[data.loc[data.apply(lambda x: np.abs(x - x.mean()) / x.std() < 5).all(axis=1), [\n",
    "    'num_video_plays', 'num_problems_attempted',\n",
    "    'num_problems_correct', 'num_subsections_viewed', 'num_forum_posts',\n",
    "    'num_forum_votes', 'avg_forum_sentiment'\n",
    "]].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>course_week</th>\n",
       "      <th>num_video_plays</th>\n",
       "      <th>num_problems_attempted</th>\n",
       "      <th>num_problems_correct</th>\n",
       "      <th>num_subsections_viewed</th>\n",
       "      <th>num_forum_posts</th>\n",
       "      <th>num_forum_votes</th>\n",
       "      <th>avg_forum_sentiment</th>\n",
       "      <th>user_started_week</th>\n",
       "      <th>user_last_active_week</th>\n",
       "      <th>user_completed_week</th>\n",
       "      <th>user_active_previous_week</th>\n",
       "      <th>user_dropped_out_next_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.560300e+05</td>\n",
       "      <td>156030.000000</td>\n",
       "      <td>156030.000000</td>\n",
       "      <td>156030.000000</td>\n",
       "      <td>156030.000000</td>\n",
       "      <td>156030.000000</td>\n",
       "      <td>156030.000000</td>\n",
       "      <td>156030.000000</td>\n",
       "      <td>156030.0</td>\n",
       "      <td>156030.000000</td>\n",
       "      <td>156030.000000</td>\n",
       "      <td>156030.000000</td>\n",
       "      <td>156030.000000</td>\n",
       "      <td>156030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.031412e+07</td>\n",
       "      <td>13.438916</td>\n",
       "      <td>3.387208</td>\n",
       "      <td>2.594975</td>\n",
       "      <td>1.821284</td>\n",
       "      <td>3.452624</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.210831</td>\n",
       "      <td>21.884618</td>\n",
       "      <td>0.454913</td>\n",
       "      <td>0.159027</td>\n",
       "      <td>0.715670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.934641e+06</td>\n",
       "      <td>10.689321</td>\n",
       "      <td>10.802378</td>\n",
       "      <td>8.372761</td>\n",
       "      <td>6.370200</td>\n",
       "      <td>6.594441</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.064486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.413809</td>\n",
       "      <td>15.808410</td>\n",
       "      <td>4.169342</td>\n",
       "      <td>0.365703</td>\n",
       "      <td>0.451096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.102000e+03</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.086111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.047784e+06</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.226006e+07</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.325213e+07</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.416629e+07</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id    course_week  num_video_plays  num_problems_attempted  \\\n",
       "count  1.560300e+05  156030.000000    156030.000000           156030.000000   \n",
       "mean   1.031412e+07      13.438916         3.387208                2.594975   \n",
       "std    3.934641e+06      10.689321        10.802378                8.372761   \n",
       "min    1.102000e+03      -1.000000         0.000000                0.000000   \n",
       "25%    8.047784e+06       6.000000         0.000000                0.000000   \n",
       "50%    1.226006e+07      10.000000         0.000000                0.000000   \n",
       "75%    1.325213e+07      18.000000         1.000000                0.000000   \n",
       "max    1.416629e+07      55.000000       118.000000               77.000000   \n",
       "\n",
       "       num_problems_correct  num_subsections_viewed  num_forum_posts  \\\n",
       "count         156030.000000           156030.000000    156030.000000   \n",
       "mean               1.821284                3.452624         0.000013   \n",
       "std                6.370200                6.594441         0.001624   \n",
       "min                0.000000                0.000000        -0.086111   \n",
       "25%                0.000000                0.000000         0.000000   \n",
       "50%                0.000000                0.000000         0.000000   \n",
       "75%                0.000000                5.000000         0.000000   \n",
       "max               59.000000               54.000000         0.089286   \n",
       "\n",
       "       num_forum_votes  avg_forum_sentiment  user_started_week  \\\n",
       "count    156030.000000             156030.0      156030.000000   \n",
       "mean          0.002730                  0.0           5.210831   \n",
       "std           0.064486                  0.0           3.413809   \n",
       "min           0.000000                  0.0          -1.000000   \n",
       "25%           0.000000                  0.0           2.000000   \n",
       "50%           0.000000                  0.0           5.000000   \n",
       "75%           0.000000                  0.0           8.000000   \n",
       "max           3.000000                  0.0          13.000000   \n",
       "\n",
       "       user_last_active_week  user_completed_week  user_active_previous_week  \\\n",
       "count          156030.000000        156030.000000              156030.000000   \n",
       "mean               21.884618             0.454913                   0.159027   \n",
       "std                15.808410             4.169342                   0.365703   \n",
       "min                -1.000000            -1.000000                   0.000000   \n",
       "25%                 9.000000            -1.000000                   0.000000   \n",
       "50%                16.000000            -1.000000                   0.000000   \n",
       "75%                35.000000            -1.000000                   0.000000   \n",
       "max                55.000000            13.000000                   1.000000   \n",
       "\n",
       "       user_dropped_out_next_week  \n",
       "count               156030.000000  \n",
       "mean                     0.715670  \n",
       "std                      0.451096  \n",
       "min                      0.000000  \n",
       "25%                      0.000000  \n",
       "50%                      1.000000  \n",
       "75%                      1.000000  \n",
       "max                      1.000000  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to reshape features into (samples, time steps, features) \n",
    "def gen_sequence(id_df, seq_length):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    data_array = id_df.values\n",
    "    num_elements = data_array.shape[0]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_array[start:stop, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_lstm():\n",
    "    \n",
    "    # build the network\n",
    "    nb_features = seq_array.shape[2]\n",
    "    nb_out = label_array.shape[1]\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "             input_shape=(sequence_length, nb_features),\n",
    "             units=100,\n",
    "             return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(LSTM(\n",
    "              units=50,\n",
    "              return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(units=nb_out, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliced, now normalizing\n",
      "Scaled, now generating sequences\n",
      "Seq Gen\n",
      "(69032, 4, 11)\n",
      "Done\n",
      "Labels Gen\n",
      "(114868, 1)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "X_cols = [\n",
    "    'user_id',\n",
    "    'course_week', 'num_video_plays', 'num_problems_attempted',\n",
    "    'num_problems_correct', 'num_subsections_viewed', 'num_forum_posts',\n",
    "    'num_forum_votes', 'avg_forum_sentiment', \n",
    "    'user_started_week', 'user_active_previous_week'\n",
    "]\n",
    "X = data[X_cols]\n",
    "y = data[['user_id', 'user_dropped_out_next_week']]\n",
    "\n",
    "\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "    \n",
    "X_train, y_train, X_val, y_val = None, None, None, None\n",
    "    \n",
    "for i, (train_ind, val_ind) in enumerate(kfold.split(X, y['user_dropped_out_next_week'])):\n",
    "\n",
    "    X_train, y_train = X.iloc[train_ind], y.iloc[train_ind]\n",
    "    X_val, y_val = X.iloc[val_ind], y.iloc[val_ind]\n",
    "    break\n",
    "    \n",
    "print('Sliced, now normalizing')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train.drop('user_id', axis=1))\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train.drop('user_id', axis=1))\n",
    "X_val_scaled = scaler.transform(X_val.drop('user_id', axis=1))\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_cols[1:])\n",
    "X_train_scaled['user_id'] = X_train['user_id']\n",
    "X_val_scaled = pd.DataFrame(X_val_scaled, columns=X_cols[1:])\n",
    "X_val_scaled['user_id'] = X_val['user_id']\n",
    "\n",
    "print('Scaled, now generating sequences')\n",
    "sequence_length = 4\n",
    "seq_gen = (list(gen_sequence(X_train_scaled[X_train_scaled['user_id']==id], sequence_length)) \n",
    "       for id in X_train_scaled['user_id'].unique())\n",
    "print('Seq Gen')\n",
    "\n",
    "# generate sequences and convert to numpy array\n",
    "seq_array = np.concatenate(sequence.pad_sequences(list(seq_gen), maxlen=4)).astype(np.float32)\n",
    "print(seq_array.shape)\n",
    "print('Done')\n",
    "\n",
    "print('Labels Gen')\n",
    "# function to generate labels\n",
    "def gen_labels(id_df, seq_length, label):\n",
    "    data_array = id_df[label].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    return data_array[seq_length:num_elements, :]\n",
    "\n",
    "# generate labels\n",
    "label_gen = [gen_labels(y_train[y_train['user_id']==id], sequence_length, ['user_dropped_out_next_week']) \n",
    "             for id in y_train['user_id'].unique()]\n",
    "\n",
    "label_array = np.concatenate(sequence.pad_sequences(list(label_gen), maxlen=4)).astype(np.float32)\n",
    "label_array.shape\n",
    "print(label_array.shape)\n",
    "print('Done')\n",
    "\n",
    "#     X_train = np.array(X_train_scaled).astype(np.float32)\n",
    "#     X_val = np.array(X_val_scaled).astype(np.float32)\n",
    "\n",
    "#     y_train = np.array(y_train).astype(np.float32)\n",
    "#     y_val = np.array(y_val).astype(np.float32)\n",
    "\n",
    "#     model = create_model(model_input, \n",
    "#                          hidden_layers_conf=layers_conf, \n",
    "#                          name='kfold-{}'.format(i))\n",
    "\n",
    "\n",
    "\n",
    "#     scores = model.evaluate(X_train[val_ind], y_train[val_ind], batch_size)\n",
    "\n",
    "#     models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "for id in X_train_scaled['user_id'].unique():\n",
    "    print(id)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104020, 11)\n",
      "(104020, 2)\n",
      "(52010, 11)\n",
      "(52010, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    1079419\n",
       "1.0      40388\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(label_array)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [1.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [1.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " [0.0],\n",
       " ...]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabirkhan/Documents/ML_Experiments/py35/lib/python3.5/site-packages/keras/backend/cntk_backend.py:2337: UserWarning: CNTK backend warning: CNTK version not detected. Will using CNTK 2.0 GA as default.\n",
      "  'CNTK backend warning: CNTK version not detected. '\n",
      "/home/kabirkhan/Documents/ML_Experiments/py35/lib/python3.5/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input85523\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n",
      "/home/kabirkhan/Documents/ML_Experiments/py35/lib/python3.5/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input83776\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 472us/step - loss: 11.5202 - acc: 0.0850 - val_loss: 11.6669 - val_acc: 0.0800\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 350us/step - loss: 11.5180 - acc: 0.1000 - val_loss: 11.6697 - val_acc: 0.0800\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 353us/step - loss: 11.5177 - acc: 0.1100 - val_loss: 11.6661 - val_acc: 0.1500\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 360us/step - loss: 11.5175 - acc: 0.1030 - val_loss: 11.6669 - val_acc: 0.1400\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 340us/step - loss: 11.5173 - acc: 0.0920 - val_loss: 11.6662 - val_acc: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa225ca8940>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy training data\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# Generate dummy validation data\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, epochs=5,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 8, 16)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([0,1,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 2, 1: 3})"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59999999999999998"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(a, np.ones(a.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.array([0.84, 0.22, 0.9, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61499999999999999"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabirkhan/Documents/ML_Experiments/py35/lib/python3.5/site-packages/keras/backend/cntk_backend.py:2337: UserWarning: CNTK backend warning: CNTK version not detected. Will using CNTK 2.0 GA as default.\n",
      "  'CNTK backend warning: CNTK version not detected. '\n"
     ]
    }
   ],
   "source": [
    "def create_model(model_input, hidden_layers_conf=[], name=''):\n",
    "    # create model\n",
    "    model = None\n",
    "    \n",
    "    for i, layer in enumerate(hidden_layers_conf):\n",
    "        \n",
    "        if i == 0:            \n",
    "            model = Dense(layer['n_units'], name='Fully_Connected_Input')(model_input)\n",
    "        else:\n",
    "            model = Dense(layer['n_units'], name='Fully_Connected_{}'.format(i + 1))(model)\n",
    "\n",
    "        model = BatchNormalization(name='Batch_Normalize_{}'.format(i + 1))(model)\n",
    "        model = Activation('relu', name='ReLU_{}'.format(i + 1))(model)\n",
    "        model = Dropout(layer.get('dropout', 0.3), name='Dropout_{}'.format(i + 1))(model)\n",
    "    \n",
    "    model = Dense(1, name='Output')(model)\n",
    "    model = BatchNormalization(name='Batch_Normalize_Output')(model)\n",
    "    predictions = Activation('sigmoid', name='Sigmoid')(model)\n",
    "    \n",
    "    model = Model(inputs=model_input, outputs=predictions)\n",
    "    if name:\n",
    "        model.name = name\n",
    "\n",
    "    return model\n",
    "\n",
    "with open('./batch_ai/params.json', 'r') as f:\n",
    "    import json\n",
    "    layers_conf = json.loads(f.read())[\"layers\"]\n",
    "\n",
    "print('Fitting model')\n",
    "# from keras.layers import \n",
    "model_input = Input(shape=(10,), name='Input')\n",
    "\n",
    "model = create_model(model_input, \n",
    "                                 hidden_layers_conf=layers_conf, \n",
    "                                 name='kfold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "Fully_Connected_Input (Dense (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "Batch_Normalize_1 (BatchNorm (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "ReLU_1 (Activation)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "Dropout_1 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "Fully_Connected_2 (Dense)    (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "Batch_Normalize_2 (BatchNorm (None, 8)                 32        \n",
      "_________________________________________________________________\n",
      "ReLU_2 (Activation)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "Dropout_2 (Dropout)          (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "Fully_Connected_3 (Dense)    (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "Batch_Normalize_3 (BatchNorm (None, 6)                 24        \n",
      "_________________________________________________________________\n",
      "ReLU_3 (Activation)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "Dropout_3 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "Fully_Connected_4 (Dense)    (None, 2)                 14        \n",
      "_________________________________________________________________\n",
      "Batch_Normalize_4 (BatchNorm (None, 2)                 8         \n",
      "_________________________________________________________________\n",
      "ReLU_4 (Activation)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "Dropout_4 (Dropout)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "Batch_Normalize_Output (Batc (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "Sigmoid (Activation)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 331\n",
      "Trainable params: 281\n",
      "Non-trainable params: 50\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
