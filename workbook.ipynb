{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_ids = data.user_id.unique()\n",
    "course_weeks = data.course_week.unique()\n",
    "\n",
    "for i, user_id in tqdm(user_ids.iteritems()):\n",
    "    print(user_id)\n",
    "    user_rows = data.loc[(data['user_id'] == user_id), :]\n",
    "\n",
    "    active_course_weeks = user_rows.loc[:, 'course_week'].unique()\n",
    "\n",
    "    zero_course_weeks = course_weeks[~course_weeks.isin(active_course_weeks.compute())]\n",
    "\n",
    "    started_week = user_rows.loc[:, 'user_started_week'].min().compute()\n",
    "    last_active_week = user_rows.loc[:, 'user_last_active_week'].min().compute()\n",
    "\n",
    "    completed_week = user_rows.loc[:, 'user_completed_week'].min().compute()\n",
    "\n",
    "#     zero_course_weeks = zero_course_weeks.between(left=0, right=int(last_active_week))\n",
    "    \n",
    "    zero_course_weeks = zero_course_weeks.loc[zero_course_weeks < int(last_active_week)]\n",
    "    \n",
    "\n",
    "    zero_course_weeks = zero_course_weeks.loc[zero_course_weeks > 0]\n",
    "\n",
    "    print(zero_course_weeks.compute())\n",
    "    \n",
    "    \n",
    "\n",
    "    zero_rows_df = pd.DataFrame(\n",
    "        np.zeros((zero_course_weeks.count().compute(), len(data.columns))),\n",
    "        columns=data.columns\n",
    "    )\n",
    "\n",
    "    zero_rows_df.loc[:, 'user_id'] = user_id\n",
    "    zero_rows_df.loc[:, 'course_week'] = zero_course_weeks\n",
    "    zero_rows_df.loc[:, 'user_started_week'] = started_week\n",
    "    zero_rows_df.loc[:, 'user_last_active_week'] = last_active_week\n",
    "    zero_rows_df.loc[:, 'user_completed_week'] = completed_week\n",
    "\n",
    "    \n",
    "    data = dd.concat([data, zero_rows_df], axis=0, interleave_partitions=True)\n",
    "#     raise ValueError('check')\n",
    "    print(data)\n",
    "#     data = data.append(zero_rows_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182112"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    46571\n",
       "1    19500\n",
       "Name: user_dropped_out_next_week, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/Microsoft+DAT206x+3T2017/model_data_l.csv')\n",
    "data['user_dropped_out_next_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = pd.read_csv('data/Microsoft+DAT247x+4T2017/model_data.csv')\n",
    "d_l = pd.read_csv('data/Microsoft+DAT247x+4T2017/model_data_l.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2533\n",
       "1     544\n",
       "Name: user_dropped_out_next_week, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['user_dropped_out_next_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    617\n",
       "1    544\n",
       "Name: user_dropped_out_next_week, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_l['user_dropped_out_next_week'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89470263243418913"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(d['user_dropped_out_next_week'], d['predicted_user_dropped_out_next_week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = d['user_dropped_out_next_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3077,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.zeros(y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82320441988950277"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(d['user_dropped_out_next_week'], np.zeros(y_true.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Course: Microsoft+DAT201x+4T2017\n",
      " did not have predictions.\n",
      "Course: Microsoft+DAT215.4x+4T2017\n",
      " did not have predictions.\n"
     ]
    }
   ],
   "source": [
    "model_accs = []\n",
    "base_accs = []\n",
    "precs = []\n",
    "recs = []\n",
    "f1s = []\n",
    "t1s = []\n",
    "cks = []\n",
    "course_ids = []\n",
    "\n",
    "\n",
    "with open('{}/top_course_ids.txt'.format('data')) as top_course_ids:\n",
    "    for top_course_id in top_course_ids:\n",
    "        if '4T2017' in top_course_id and 'JPN' not in top_course_id and 'DAT102x' not in top_course_id:\n",
    "            try:\n",
    "                final = pd.read_csv('data/{}/model_data_with_preds_l.csv'.format(top_course_id.strip()))\n",
    "                course_ids.append(top_course_id.strip())\n",
    "                y_true = final['user_dropped_out_next_week']\n",
    "                y_pred = final['predicted_user_dropped_out_next_week']\n",
    "            except:\n",
    "                print('Course: {} did not have predictions.'.format(top_course_id))\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            base_acc = np.zeros(y_true.shape)\n",
    "\n",
    "\n",
    "            model_accs.append(accuracy_score(y_true, y_pred))\n",
    "            base_accs.append(accuracy_score(y_true, base_acc))\n",
    "\n",
    "\n",
    "            precs.append(precision_score(y_true, y_pred))\n",
    "            recs.append(recall_score(y_true, y_pred))\n",
    "            \n",
    "            f1s.append(f1_score(y_true, y_pred))\n",
    "\n",
    "            conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "            t1s.append(conf_matrix[1][0] / len(y_true))\n",
    "\n",
    "            cks.append(cohen_kappa_score(y_true, y_pred))\n",
    "                \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(\n",
    "    [],\n",
    "    columns=[\n",
    "        'course_id', 'model_accuracy', 'base_accuracy (all 0)',\n",
    "        'precision', 'recall', 'f1_score', 'num_false_negatives',\n",
    "        'cohens_kappa'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores['course_id'] = course_ids\n",
    "scores['model_accuracy'] = model_accs\n",
    "scores['base_accuracy (all 0)'] = base_accs\n",
    "# scores['precision'] = precs\n",
    "scores['recall'] = recs\n",
    "scores['f1_score'] = f1s\n",
    "scores['false_neg_perc'] = t1s\n",
    "scores['cohens_kappa'] = cks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_accuracy</th>\n",
       "      <th>base_accuracy (all 0)</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>cohens_kappa</th>\n",
       "      <th>false_neg_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>34.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.684881</td>\n",
       "      <td>0.433035</td>\n",
       "      <td>0.891028</td>\n",
       "      <td>0.757141</td>\n",
       "      <td>0.307221</td>\n",
       "      <td>0.061064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.039352</td>\n",
       "      <td>0.092054</td>\n",
       "      <td>0.047550</td>\n",
       "      <td>0.052653</td>\n",
       "      <td>0.053306</td>\n",
       "      <td>0.029501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.615760</td>\n",
       "      <td>0.244774</td>\n",
       "      <td>0.744044</td>\n",
       "      <td>0.665376</td>\n",
       "      <td>0.183833</td>\n",
       "      <td>0.019920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.648871</td>\n",
       "      <td>0.346731</td>\n",
       "      <td>0.868089</td>\n",
       "      <td>0.719372</td>\n",
       "      <td>0.278210</td>\n",
       "      <td>0.040122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.684636</td>\n",
       "      <td>0.461572</td>\n",
       "      <td>0.896361</td>\n",
       "      <td>0.748100</td>\n",
       "      <td>0.314175</td>\n",
       "      <td>0.056655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.716498</td>\n",
       "      <td>0.495224</td>\n",
       "      <td>0.928215</td>\n",
       "      <td>0.809384</td>\n",
       "      <td>0.338812</td>\n",
       "      <td>0.073257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.769920</td>\n",
       "      <td>0.580146</td>\n",
       "      <td>0.971510</td>\n",
       "      <td>0.855172</td>\n",
       "      <td>0.408120</td>\n",
       "      <td>0.166392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_accuracy  base_accuracy (all 0)     recall   f1_score  \\\n",
       "count       34.000000              34.000000  34.000000  34.000000   \n",
       "mean         0.684881               0.433035   0.891028   0.757141   \n",
       "std          0.039352               0.092054   0.047550   0.052653   \n",
       "min          0.615760               0.244774   0.744044   0.665376   \n",
       "25%          0.648871               0.346731   0.868089   0.719372   \n",
       "50%          0.684636               0.461572   0.896361   0.748100   \n",
       "75%          0.716498               0.495224   0.928215   0.809384   \n",
       "max          0.769920               0.580146   0.971510   0.855172   \n",
       "\n",
       "       cohens_kappa  false_neg_perc  \n",
       "count     34.000000       34.000000  \n",
       "mean       0.307221        0.061064  \n",
       "std        0.053306        0.029501  \n",
       "min        0.183833        0.019920  \n",
       "25%        0.278210        0.040122  \n",
       "50%        0.314175        0.056655  \n",
       "75%        0.338812        0.073257  \n",
       "max        0.408120        0.166392  "
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cntk.device import try_set_default_device, gpu\n",
    "try_set_default_device(gpu(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from cntk.device import try_set_default_device, gpu\n",
    "try_set_default_device(gpu(0))\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Activation, Dense, Dropout, Input, Average\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.utils import plot_model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from pipeline.util import *\n",
    "\n",
    "\n",
    "def get_data_path():\n",
    "    return './data'\n",
    "\n",
    "def save_df_to_file(dataframe, name, course_id, type='csv'):\n",
    "    \"\"\"\n",
    "    Save a dataframe to a csv file in the data/{course_id}/ directory\n",
    "    \"\"\"\n",
    "\n",
    "    path = '{}/{}/{}'.format(get_data_path(), course_id, name)\n",
    "\n",
    "    if type == 'excel':\n",
    "        path += '.xlsx'\n",
    "        create_directory_safe(path)\n",
    "        dataframe.to_excel(path)\n",
    "    else:\n",
    "        path += '.csv'\n",
    "        create_directory_safe(path)\n",
    "        dataframe.to_csv(path, index=False)\n",
    "        \n",
    "        \n",
    "def get_data(current_course_id):\n",
    "    \"\"\"\n",
    "    TODO Fix how this training data is sampled\n",
    "    e.g. bootstrap sampling of a random number of courses\n",
    "    to get a total of > 1 million training samples\n",
    "    \"\"\"\n",
    "\n",
    "    # train = pd.read_csv('{}/{}/model_data.csv'.format(get_data_path(), 'Microsoft+DAT206x+3T2017'))\n",
    "    train = None\n",
    "    past_course_ids = [f for f in os.listdir(get_data_path()) if not f.startswith('.')]\n",
    "    try:\n",
    "        past_course_ids.remove(current_course_id)\n",
    "    except ValueError:\n",
    "        print('Not in list')\n",
    "\n",
    "    for course_id in past_course_ids:\n",
    "        if '4T2017' not in course_id:\n",
    "            try:\n",
    "                # course_run_data = pd.read_csv('{}/{}/model_data.csv'.format(get_data_path(), course_id))\n",
    "                path = '{}/{}/model_data_l.csv'.format(get_data_path(), course_id)\n",
    "                course_run_data = pd.read_csv(path)\n",
    "            except Exception:\n",
    "                print('model_data.csv does not exist for course: ', course_id)\n",
    "                continue\n",
    "                # pass                \n",
    "            if train is None:\n",
    "                train = course_run_data\n",
    "            else:\n",
    "                train = train.append(course_run_data)\n",
    "\n",
    "    print('Training data done.')\n",
    "\n",
    "    train = train.reset_index(drop=True)\n",
    "    # test = pd.read_csv('{}/{}/model_data.csv'.format(get_data_path(), current_course_id))\n",
    "    test = pd.read_csv('{}/{}/model_data_l.csv'.format(get_data_path(), current_course_id))\n",
    "\n",
    "    X_cols = [\n",
    "        'course_week', 'num_video_plays', 'num_problems_attempted',\n",
    "        'num_problems_correct', 'num_subsections_viewed', 'num_forum_posts',\n",
    "        'num_forum_votes', 'avg_forum_sentiment', \n",
    "        'user_started_week', 'user_active_previous_week'\n",
    "    ]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train[X_cols])\n",
    "\n",
    "    X_train = scaler.transform(train[X_cols])\n",
    "    X_test = scaler.transform(test[X_cols])\n",
    "\n",
    "    X_train = np.array(X_train).astype(np.float32)\n",
    "    X_test = np.array(X_test).astype(np.float32)\n",
    "\n",
    "    y_train = np.array(train['user_dropped_out_next_week']).astype(np.float32)\n",
    "    y_test = np.array(test['user_dropped_out_next_week']).astype(np.float32)\n",
    "\n",
    "    return (X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "def _create_pivot_table(df, val_col):\n",
    "    df_pivot = df.pivot_table(\n",
    "        index='user_id', columns=['course_week'], values=val_col, fill_value=-1\n",
    "    )\n",
    "    df_colored = df_pivot.style.applymap(_cell_colors)\n",
    "    return df_colored\n",
    "\n",
    "def _cell_colors(s):\n",
    "    ret = 'background-color: {}'\n",
    "    if s == 0:\n",
    "        ret = ret.format('#228b22')\n",
    "    elif s == 1:\n",
    "        ret = ret.format('#dc143c')\n",
    "    else:\n",
    "        ret = ret.format('#d3d3d3')\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(model_input, hidden_layers_conf=[], name=''):\n",
    "    # create model\n",
    "    model = None\n",
    "    \n",
    "    for i, layer in enumerate(hidden_layers_conf):\n",
    "        \n",
    "        if i == 0:            \n",
    "            model = Dense(layer['n_units'])(model_input)            \n",
    "                \n",
    "        model = BatchNormalization()(model)\n",
    "        model = Activation('relu')(model)\n",
    "        model = Dropout(layer.get('dropout', 0.2))(model)\n",
    "    \n",
    "    model = Dense(1)(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    predictions = Activation('sigmoid')(model)\n",
    "    \n",
    "    model = Model(inputs=model_input, outputs=predictions)\n",
    "    if name:\n",
    "        model.name = name\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_and_train(model, x_train, y_train, optimizer='adam', metrics=['accuracy'], num_epochs=20, batch_size=100): \n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=metrics) \n",
    "    filepath = 'weights/' + model.name + '.{epoch:02d}-{loss:.2f}.hdf5'\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath, monitor='loss', verbose=0, save_weights_only=True, save_best_only=True, mode='auto', period=1\n",
    "    )\n",
    "    \n",
    "    history = model.fit(x=x_train,\n",
    "                        y=y_train, \n",
    "                        batch_size=batch_size, \n",
    "                        epochs=num_epochs, \n",
    "                        verbose=1,\n",
    "                        class_weight={ 0: 1., 1: 2 },\n",
    "                        callbacks=[checkpoint])\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def ensemble_models(models, model_input):\n",
    "    # collect outputs of models in a list\n",
    "    print(models[0].outputs)\n",
    "    model_outputs = [model.outputs[0] for model in models]\n",
    "    \n",
    "    print('OUTPUTS:')\n",
    "    print(model_outputs)\n",
    "\n",
    "    # averaging outputs\n",
    "    avg = Average()(model_outputs)\n",
    "    \n",
    "    print('AVG:')\n",
    "    print(avg)\n",
    "\n",
    "    # build model from same input and avg output\n",
    "    model_ens = Model(inputs=model_input, outputs=avg, name='ensemble') \n",
    "    print(model_ens)\n",
    "   \n",
    "    return model_ens\n",
    "\n",
    "\n",
    "def fit_score_predict(course_id, train=False):\n",
    "\n",
    "    print('GETTING DATA: ')\n",
    "    X_train, y_train, X_test, y_test = get_data(course_id)\n",
    "    print('Done.')\n",
    "\n",
    "    input_shape = (X_train.shape[1],)\n",
    "    model_input = Input(shape=input_shape)\n",
    "    \n",
    "    models = []\n",
    "    batch_size = 256\n",
    "    \n",
    "    if not train:\n",
    "        current_date_string = datetime.strftime(datetime.today(), '%Y-%m-%d')\n",
    "        model = load_model('model.h5-{}'.format('2018-01-23'))\n",
    "    else:\n",
    "        adam = optimizers.Adam(lr=0.01)\n",
    "        layers_conf = [\n",
    "            {\n",
    "                'n_units': 8,\n",
    "                'dropout': 0.2,\n",
    "                'input_dim': 10\n",
    "            },\n",
    "            {\n",
    "                'n_units': 8,\n",
    "                'dropout': 0.25\n",
    "            },\n",
    "            {\n",
    "                'n_units': 6,\n",
    "                'dropout': 0.2\n",
    "            },\n",
    "            {\n",
    "                'n_units': 2,\n",
    "                'dropout': 0.\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        print('Fitting model')\n",
    "        \n",
    "        kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "        \n",
    "        \n",
    "        for i, (train_ind, val_ind) in enumerate(kfold.split(X_train, y_train)):\n",
    "            \n",
    "            model = create_model(model_input, \n",
    "                                 hidden_layers_conf=layers_conf, \n",
    "                                 name='kfold-{}'.format(i))\n",
    "            \n",
    "            _ = compile_and_train(model,\n",
    "                                  num_epochs=3,\n",
    "                                  batch_size=batch_size,\n",
    "                                  train_data=(X_train[train_ind], y_train[train_ind]), \n",
    "                                  validation_data=(X_train[val_ind], y_train[val_ind]))            \n",
    "            \n",
    "            scores = model.evaluate(X_train[val_ind], y_train[val_ind], batch_size)\n",
    "            \n",
    "            models.append(model)\n",
    "        \n",
    "    print('Evaluating model on data for course: {}'.format(course_id))\n",
    "    \n",
    "    print(model_input)\n",
    "    ensemble = ensemble_models(models, model_input)\n",
    "\n",
    "    print('Done')\n",
    "\n",
    "    try:\n",
    "        current_date_string = datetime.strftime(datetime.today(), '%Y-%m-%d')\n",
    "        ensemble.save('model-ensemble-{}.h5'.format(current_date_string))\n",
    "    except:\n",
    "        print('FAILED TO SAVE MODEL')\n",
    "    \n",
    "#     score = ensemble.evaluate(X_test, y_test, batch_size)\n",
    "#     print('Model score', score)\n",
    "\n",
    "    preds = ensemble.predict(X_test, batch_size)\n",
    "    final_preds = np.round(preds)\n",
    "\n",
    "    print('PREDS: ', final_preds)\n",
    "    print('Y_TEST: ', y_test)\n",
    "\n",
    "    conf_matrix = metrics.confusion_matrix(y_test, final_preds)\n",
    "\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "    total = len(y_test)\n",
    "    final_acc = (tn + tp) / total\n",
    "\n",
    "    test_data_orig = pd.read_csv('{}/{}/model_data_l.csv'.format(get_data_path(), course_id))\n",
    "    test_data_orig['predicted_user_dropped_out_next_week'] = final_preds\n",
    "    \n",
    "\n",
    "    pred_pivot = _create_pivot_table(test_data_orig, 'predicted_user_dropped_out_next_week')\n",
    "    real_pivot = _create_pivot_table(test_data_orig, 'user_dropped_out_next_week')\n",
    "\n",
    "    # save_df_to_file(pred_pivot, 'predicted_dropouts', course_id, type='excel')\n",
    "    # save_df_to_file(real_pivot, 'real_dropouts', course_id, type='excel')\n",
    "    # save_df_to_file(test_data_orig, 'model_data_with_preds', course_id)\n",
    "\n",
    "#     save_df_to_file(pred_pivot, 'predicted_dropouts_l', course_id, type='excel')\n",
    "#     save_df_to_file(real_pivot, 'real_dropouts_l', course_id, type='excel')\n",
    "    save_df_to_file(test_data_orig, 'model_data_with_preds_l', course_id)\n",
    "\n",
    "    print('ACCURACY: ', final_acc)\n",
    "    print('CONFUSION MATRIX: ')\n",
    "    print(conf_matrix)\n",
    "    print(conf_matrix / len(y_test))\n",
    "\n",
    "    return (final_preds, final_acc, conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GETTING DATA: \n",
      "model_data.csv does not exist for course:  Microsoft+DAT215.4x+1T2017\n",
      "model_data.csv does not exist for course:  _SUCCESS\n",
      "model_data.csv does not exist for course:  Microsoft+DAT206x+JPN+1T2017\n",
      "model_data.csv does not exist for course:  Microsoft+DAT206x+6T2016\n",
      "model_data.csv does not exist for course:  Microsoft+DAT206x+1T2018\n",
      "model_data.csv does not exist for course:  Microsoft+DAT215.3x+3T2017\n",
      "model_data.csv does not exist for course:  Microsoft+DAT206x+JPN+2T2017\n",
      "model_data.csv does not exist for course:  Microsoft+DAT207x+1T2018\n",
      "model_data.csv does not exist for course:  weights\n",
      "model_data.csv does not exist for course:  top_course_ids.txt\n",
      "model_data.csv does not exist for course:  Microsoft+DAT205x+3T2016\n",
      "Training data done.\n",
      "Done.\n",
      "(10,)\n",
      "Fitting model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabirkhan/Documents/ML_Experiments/py35/lib/python3.5/site-packages/keras/backend/cntk_backend.py:2337: UserWarning: CNTK backend warning: CNTK version not detected. Will using CNTK 2.0 GA as default.\n",
      "  'CNTK backend warning: CNTK version not detected. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "    800/1317788 [..............................] - ETA: 5:29 - loss: 1.1895 - acc: 0.5062 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabirkhan/Documents/ML_Experiments/py35/lib/python3.5/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input75544\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317788/1317788 [==============================] - 100s 76us/step - loss: 0.6831 - acc: 0.7302\n",
      "658894/658894 [==============================] - 5s 8us/step\n",
      "acc: 75.15%\n",
      "Epoch 1/1\n",
      "    800/1317788 [..............................] - ETA: 5:41 - loss: 1.3244 - acc: 0.5400 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabirkhan/Documents/ML_Experiments/py35/lib/python3.5/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input78354\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317788/1317788 [==============================] - 100s 76us/step - loss: 0.7114 - acc: 0.7264\n",
      "658894/658894 [==============================] - 5s 8us/step\n",
      "acc: 73.85%\n",
      "Epoch 1/1\n",
      "    700/1317788 [..............................] - ETA: 6:47 - loss: 1.2663 - acc: 0.4243 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kabirkhan/Documents/ML_Experiments/py35/lib/python3.5/site-packages/cntk/core.py:361: UserWarning: your data is of type \"float64\", but your input variable (uid \"Input81164\") expects \"<class 'numpy.float32'>\". Please convert your data beforehand to speed up training.\n",
      "  (sample.dtype, var.uid, str(var.dtype)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317788/1317788 [==============================] - 100s 76us/step - loss: 0.6976 - acc: 0.7264\n",
      "658894/658894 [==============================] - 5s 8us/step\n",
      "acc: 77.02%\n",
      "AVERAGE ACCURACY MANUAL: 75.34% (+/- 1.30%)\n",
      "Evaluating model on data for course: Microsoft+DAT206x+4T2017\n",
      "Input('input_18', [#], [10])\n",
      "[Composite(StableSigmoid): Input('input_18', [#], [10]) -> Output('StableSigmoid75535_Output_0', [#], [1])]\n",
      "OUTPUTS:\n",
      "[Composite(StableSigmoid): Input('input_18', [#], [10]) -> Output('StableSigmoid75535_Output_0', [#], [1]), Composite(StableSigmoid): Input('input_18', [#], [10]) -> Output('StableSigmoid78345_Output_0', [#], [1]), Composite(StableSigmoid): Input('input_18', [#], [10]) -> Output('StableSigmoid81155_Output_0', [#], [1])]\n",
      "AVG:\n",
      "Composite(input_18: Tensor[10]) -> Tensor[1]\n",
      "<keras.engine.training.Model object at 0x7fa24428fe10>\n",
      "Done\n",
      "PREDS:  [[ 1.]\n",
      " [ 0.]\n",
      " [ 1.]\n",
      " ..., \n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "Y_TEST:  [ 0.  0.  1. ...,  0.  1.  1.]\n",
      "ACCURACY:  0.740426738133\n",
      "CONFUSION MATRIX: \n",
      "[[ 9330  7744]\n",
      " [ 2329 19403]]\n",
      "[[ 0.24042674  0.19955677]\n",
      " [ 0.06001649  0.5       ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 1.],\n",
       "        [ 0.],\n",
       "        [ 1.],\n",
       "        ..., \n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.]], dtype=float32), 0.74042673813327831, array([[ 9330,  7744],\n",
       "        [ 2329, 19403]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_score_predict('Microsoft+DAT206x+4T2017', train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "ensemble = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = np.array([1,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,0,1,1,0,1,1,0,0,1,1,1,0,1,0])\n",
    "y_pred = np.array([1,1,1,0,0,1,1,0,0,1,1,0,0,1,1,1,1,1,0,0,1,1,0,0,1,1,0,0,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83333333333333337"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = metrics.confusion_matrix(y_true, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88235294117647056"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensitivity = tp / float(fn + tp)\n",
    "sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88235294117647056"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11764705882352941"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn / float(tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82579185520361975"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049019607843137192"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.recall_score(y_true, y_pred) - metrics.accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>course_week</th>\n",
       "      <th>num_video_plays</th>\n",
       "      <th>num_problems_attempted</th>\n",
       "      <th>num_problems_correct</th>\n",
       "      <th>num_subsections_viewed</th>\n",
       "      <th>num_forum_posts</th>\n",
       "      <th>num_forum_votes</th>\n",
       "      <th>avg_forum_sentiment</th>\n",
       "      <th>user_started_week</th>\n",
       "      <th>user_last_active_week</th>\n",
       "      <th>user_completed_week</th>\n",
       "      <th>user_active_previous_week</th>\n",
       "      <th>user_dropped_out_next_week</th>\n",
       "      <th>predicted_user_dropped_out_next_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54812.970000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.700000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>2.670000</td>\n",
       "      <td>5.460000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.210000</td>\n",
       "      <td>9.020000</td>\n",
       "      <td>-0.780000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>27943.162048</td>\n",
       "      <td>4.211576</td>\n",
       "      <td>19.145113</td>\n",
       "      <td>11.704199</td>\n",
       "      <td>8.520984</td>\n",
       "      <td>8.832241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.962032</td>\n",
       "      <td>5.235813</td>\n",
       "      <td>1.547758</td>\n",
       "      <td>0.429235</td>\n",
       "      <td>0.479372</td>\n",
       "      <td>0.422953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1131.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33522.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58444.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82020.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>84693.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id  course_week  num_video_plays  num_problems_attempted  \\\n",
       "count    100.000000   100.000000       100.000000              100.000000   \n",
       "mean   54812.970000     7.000000         8.700000                3.960000   \n",
       "std    27943.162048     4.211576        19.145113               11.704199   \n",
       "min     1131.000000     1.000000         0.000000                0.000000   \n",
       "25%    33522.000000     3.000000         0.000000                0.000000   \n",
       "50%    58444.000000     7.000000         1.000000                0.000000   \n",
       "75%    82020.000000    10.000000         8.500000                2.250000   \n",
       "max    84693.000000    16.000000       111.000000              101.000000   \n",
       "\n",
       "       num_problems_correct  num_subsections_viewed  num_forum_posts  \\\n",
       "count            100.000000              100.000000            100.0   \n",
       "mean               2.670000                5.460000              0.0   \n",
       "std                8.520984                8.832241              0.0   \n",
       "min                0.000000                0.000000              0.0   \n",
       "25%                0.000000                0.000000              0.0   \n",
       "50%                0.000000                4.000000              0.0   \n",
       "75%                2.000000                7.000000              0.0   \n",
       "max               76.000000               68.000000              0.0   \n",
       "\n",
       "       num_forum_votes  avg_forum_sentiment  user_started_week  \\\n",
       "count            100.0                100.0         100.000000   \n",
       "mean               0.0                  0.0           5.210000   \n",
       "std                0.0                  0.0           2.962032   \n",
       "min                0.0                  0.0           1.000000   \n",
       "25%                0.0                  0.0           3.000000   \n",
       "50%                0.0                  0.0           6.000000   \n",
       "75%                0.0                  0.0           7.000000   \n",
       "max                0.0                  0.0          13.000000   \n",
       "\n",
       "       user_last_active_week  user_completed_week  user_active_previous_week  \\\n",
       "count             100.000000           100.000000                 100.000000   \n",
       "mean                9.020000            -0.780000                   0.240000   \n",
       "std                 5.235813             1.547758                   0.429235   \n",
       "min                 1.000000            -1.000000                   0.000000   \n",
       "25%                 4.000000            -1.000000                   0.000000   \n",
       "50%                 8.000000            -1.000000                   0.000000   \n",
       "75%                15.000000            -1.000000                   0.000000   \n",
       "max                16.000000            10.000000                   1.000000   \n",
       "\n",
       "       user_dropped_out_next_week  predicted_user_dropped_out_next_week  \n",
       "count                  100.000000                            100.000000  \n",
       "mean                     0.650000                              0.770000  \n",
       "std                      0.479372                              0.422953  \n",
       "min                      0.000000                              0.000000  \n",
       "25%                      0.000000                              1.000000  \n",
       "50%                      1.000000                              1.000000  \n",
       "75%                      1.000000                              1.000000  \n",
       "max                      1.000000                              1.000000  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_video_plays</th>\n",
       "      <th>num_problems_attempted</th>\n",
       "      <th>num_problems_correct</th>\n",
       "      <th>num_subsections_viewed</th>\n",
       "      <th>num_forum_posts</th>\n",
       "      <th>num_forum_votes</th>\n",
       "      <th>avg_forum_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.700000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>2.670000</td>\n",
       "      <td>5.460000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.145113</td>\n",
       "      <td>11.704199</td>\n",
       "      <td>8.520984</td>\n",
       "      <td>8.832241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>111.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       num_video_plays  num_problems_attempted  num_problems_correct  \\\n",
       "count       100.000000              100.000000            100.000000   \n",
       "mean          8.700000                3.960000              2.670000   \n",
       "std          19.145113               11.704199              8.520984   \n",
       "min           0.000000                0.000000              0.000000   \n",
       "25%           0.000000                0.000000              0.000000   \n",
       "50%           1.000000                0.000000              0.000000   \n",
       "75%           8.500000                2.250000              2.000000   \n",
       "max         111.000000              101.000000             76.000000   \n",
       "\n",
       "       num_subsections_viewed  num_forum_posts  num_forum_votes  \\\n",
       "count              100.000000            100.0            100.0   \n",
       "mean                 5.460000              0.0              0.0   \n",
       "std                  8.832241              0.0              0.0   \n",
       "min                  0.000000              0.0              0.0   \n",
       "25%                  0.000000              0.0              0.0   \n",
       "50%                  4.000000              0.0              0.0   \n",
       "75%                  7.000000              0.0              0.0   \n",
       "max                 68.000000              0.0              0.0   \n",
       "\n",
       "       avg_forum_sentiment  \n",
       "count                100.0  \n",
       "mean                   0.0  \n",
       "std                    0.0  \n",
       "min                    0.0  \n",
       "25%                    0.0  \n",
       "50%                    0.0  \n",
       "75%                    0.0  \n",
       "max                    0.0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h[['num_video_plays', 'num_problems_attempted',\n",
    "       'num_problems_correct', 'num_subsections_viewed', 'num_forum_posts',\n",
    "       'num_forum_votes', 'avg_forum_sentiment']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
